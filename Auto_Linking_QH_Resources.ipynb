{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMXpLuQcOvMuT9teY7mk7aG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibtisam-a/Integrated-Islamic-Ontology/blob/main/Auto_Linking_QH_Resources.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvgJZb3hhuFF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas rdflib openpyxl"
      ],
      "metadata": {
        "id": "i4p_VUZqhvm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from rdflib import Graph, Namespace, URIRef, Literal\n",
        "from rdflib.namespace import RDF, RDFS"
      ],
      "metadata": {
        "id": "2P4ZuGlMhvXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Excel file\n",
        "file_path = 'file-name.xlsx'  # Replace with your file path\n",
        "df = pd.read_excel(file_path)\n",
        "# Show the first few rows\n",
        "#print(df.head())\n"
      ],
      "metadata": {
        "id": "xy9fq_cIh81Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------\n",
        "# Step 1: Imports & Graph Initialization\n",
        "# ----------------------\n",
        "\n",
        "from rdflib import Graph, Namespace, RDF, RDFS, OWL, Literal\n",
        "\n",
        "# Create RDF graph\n",
        "g = Graph()\n",
        "\n",
        "# Define namespace\n",
        "ns = Namespace(\"http://IslamicOntology.org/Resources#\")#our ontology namespace\n",
        "g.bind(\"ibs\", ns)\n",
        "g.bind(\"rdfs\", RDFS)\n",
        "\n",
        "# ----------------------\n",
        "# Step 2: Define Classes\n",
        "# ----------------------\n",
        "# -------- 2Ô∏è‚É£ Define all classes --------\n",
        "classes = {\n",
        "    \"IslamicBooks\": None,\n",
        "    \"HadithBook\": \"IslamicBooks\",\n",
        "    \"Quran\": \"IslamicBooks\",\n",
        "    \"QuranChapter\": \"IslamicBooks\",\n",
        "    \"Verse\": \"IslamicBooks\",\n",
        "    \"QuranicWord\": \"IslamicBooks\",\n",
        "    \"QuranicSegment\":\"IslamicBooks\",\n",
        "    \"QuranTopic\": \"IslamicBooks\",\n",
        "\n",
        "    \"SunanAbuDawood\": \"HadithBook\",\n",
        "    \"SahihAlBukhari\": \"HadithBook\",\n",
        "    \"SunanIbnMajah\": \"HadithBook\",\n",
        "    \"SahihMuslim\": \"HadithBook\",\n",
        "   \"SunanAnNasai\": \"HadithBook\",\n",
        "    \"JamiAtTirmidhi\": \"HadithBook\",\n",
        "\n",
        "\n",
        "    \"HadithChapter\": \"IslamicBooks\",\n",
        "    \"HadithText\": \"IslamicBooks\",\n",
        "    \"HadithTopic\": \"IslamicBooks\",\n",
        "}\n",
        "# Class labels in English and Arabic\n",
        "class_labels = {\n",
        "    \"IslamicBooks\": {\"en\": \"Islamic Books\", \"ar\": \"ÿßŸÑŸÖŸàÿßÿ±ÿØ ÿßŸÑÿ•ÿ≥ŸÑÿßŸÖŸäÿ©\"},\n",
        "    \"Quran\": {\"en\": \"Quran\", \"ar\": \"ÿßŸÑŸÇÿ±ÿ¢ŸÜ\"},\n",
        "    \"QuranChapter\": {\"en\": \"Quran Chapter\", \"ar\": \"ÿ≥Ÿàÿ±ÿ©\"},\n",
        "    \"Verse\": {\"en\": \"Quran Verse\", \"ar\": \"ÿ¢Ÿäÿ©\"},\n",
        "    \"QuranicWord\": {\"en\": \"Quran Word\", \"ar\": \"ŸÉŸÑŸÖÿ© ŸÇÿ±ÿ¢ŸÜŸäÿ©\"},\n",
        "    \"QuranicSegment\": {\"en\": \"Quran Segment\", \"ar\": \"ŸÖŸÇÿ∑ÿπ ŸÇÿ±ÿ¢ŸÜŸä\"},\n",
        "    \"QuranTopic\": {\"en\": \"Quran Topic\", \"ar\": \"ŸÖŸàÿ∂Ÿàÿπ ŸÇÿ±ÿ¢ŸÜŸä\"},\n",
        "\n",
        "    \"HadithBook\": {\"en\": \"Hadith Book\", \"ar\": \"ŸÉÿ™ÿßÿ® ÿ≠ÿØŸäÿ´\"},\n",
        "    \"SahihAlBukhari\": {\"en\": \"Sahih Al-Bukhari\", \"ar\": \"ÿµÿ≠Ÿäÿ≠ ÿßŸÑÿ®ÿÆÿßÿ±Ÿä\"},\n",
        "    \"SahihMuslim\": {\"en\": \"Sahih Muslim\", \"ar\": \"ÿµÿ≠Ÿäÿ≠ ŸÖÿ≥ŸÑŸÖ\"},\n",
        "    \"SunanAbuDawood\": {\"en\": \"Sunan Abu Dawood\", \"ar\": \"ÿ≥ŸÜŸÜ ÿ£ÿ®Ÿä ÿØÿßŸàÿØ\"},\n",
        "    \"JamiAtTirmidhi\": {\"en\": \"Jami' At-Tirmidhi\", \"ar\": \"ÿ¨ÿßŸÖÿπ ÿßŸÑÿ™ÿ±ŸÖÿ∞Ÿä\"},\n",
        "    \"SunanAnNasai\": {\"en\": \"Sunan An-Nasa'i\", \"ar\": \"ÿ≥ŸÜŸÜ ÿßŸÑŸÜÿ≥ÿßÿ¶Ÿä\"},\n",
        "    \"SunanIbnMajah\": {\"en\": \"Sunan Ibn Majah\", \"ar\": \"ÿ≥ŸÜŸÜ ÿßÿ®ŸÜ ŸÖÿßÿ¨Ÿá\"},\n",
        "    \"HadithChapter\": {\"en\": \"Hadith Chapter\", \"ar\": \"ÿ®ÿßÿ® ÿßŸÑÿ≠ÿØŸäÿ´\"},\n",
        "    \"HadithText\": {\"en\": \"Hadith Text\", \"ar\": \"ŸÜÿµ ÿßŸÑÿ≠ÿØŸäÿ´\"},\n",
        "    \"HadithTopic\": {\"en\":\"Hadith Topic\", \"ar\": \"ŸÖŸàÿ∂Ÿàÿπ ÿßŸÑÿ≠ÿØŸäÿ´\"},\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Create classes, subclass relationships, and labels\n",
        "for cls, parent in classes.items():\n",
        "    cls_uri = ns[cls]\n",
        "    g.add((cls_uri, RDF.type, OWL.Class))\n",
        "    if parent:\n",
        "        parent_uri = ns[parent]\n",
        "        g.add((cls_uri, RDFS.subClassOf, parent_uri))\n",
        "\n",
        "    # Add English and Arabic labels if available\n",
        "    if cls in class_labels:\n",
        "        labels = class_labels[cls]\n",
        "        g.add((cls_uri, RDFS.label, Literal(labels['en'], lang='en')))\n",
        "        g.add((cls_uri, RDFS.label, Literal(labels['ar'], lang='ar')))\n",
        "\n"
      ],
      "metadata": {
        "id": "3Z03Bo1ih8gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding Hadith Books as RDF.type of HadithBook class\n",
        "g.add((ns.SahihMuslim, RDF.type, ns.HadithBook))\n",
        "g.add((ns.JamiAtTirmidhi, RDF.type, ns.HadithBook))\n",
        "g.add((ns.SunanAbuDawood, RDF.type, ns.HadithBook))\n",
        "g.add((ns.SunanIbnMajah, RDF.type, ns.HadithBook))\n",
        "g.add((ns.SunanAnNasai, RDF.type, ns.HadithBook))\n",
        "g.add((ns.SahihAlBukhari, RDF.type, ns.HadithBook))\n",
        "\n"
      ],
      "metadata": {
        "id": "sqaMN7jVh8TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ResUmQBsi-kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Define Quran and Hadith object properties --------\n",
        "from rdflib.namespace import XSD\n",
        "\n",
        "# Define Quran object and Data properties\n",
        "isPartOfQ = ns.isPartOfQ\n",
        "discussQuranTopics = ns.discussQuranTopics\n",
        "hasQWord = ns.hasQWord\n",
        "hasQSegment = ns.hasQSegment\n",
        "isPartOfVerse = ns.isPartOfVerse\n",
        "isPartOfWord = ns.isPartOfWord\n",
        "hasBuckwalterSegment = ns.hasBuckwalterSegment\n",
        "hasPOS = ns.hasPOS\n",
        "hasTafsirByJalalayn = ns.hasTafsirByJalalayn\n",
        "hasTafsirByMuyasser = ns.hasTafsirByMuyasser\n",
        "hasQuranicConcept = ns.hasQuranicConcept\n",
        "\n",
        "# ===========================\n",
        "#Quran Object Properties\n",
        "# ===========================\n",
        "g.add((isPartOfQ, RDF.type, OWL.ObjectProperty))\n",
        "g.add((isPartOfQ, RDFS.domain, ns.Verse))\n",
        "g.add((isPartOfQ, RDFS.range, ns.QuranChapter))#we need to edit it QuranChapter\n",
        "g.add((isPartOfQ, RDFS.label, Literal(\"Is Part Of\", lang=\"en\")))\n",
        "g.add((isPartOfQ, RDFS.label, Literal(\"ÿ¨ÿ≤ÿ° ŸÖŸÜ\", lang=\"ar\")))\n",
        "\n",
        "# hasWord: Verse ‚Üí Word\n",
        "g.add((ns.hasQWord, RDF.type, OWL.ObjectProperty))\n",
        "g.add((ns.hasQWord, RDFS.domain, ns.Verse))\n",
        "g.add((ns.hasQWord, RDFS.range, ns.QuranicWord))\n",
        "g.add((ns.hasQWord, RDFS.label, Literal(\"Has Quranic Word\", lang=\"en\")))\n",
        "g.add((ns.hasQWord, RDFS.label, Literal(\"Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ŸÉŸÑŸÖÿ© ŸÇÿ±ÿ¢ŸÜŸäÿ©\", lang=\"ar\")))\n",
        "\n",
        "# hasSegment: Word ‚Üí Segment\n",
        "g.add((ns.hasQSegment, RDF.type, OWL.ObjectProperty))#\"QuranicSegmen\n",
        "g.add((ns.hasQSegment, RDFS.domain, ns.QuranicWord))\n",
        "g.add((ns.hasQSegment, RDFS.range, ns.QuranicSegment))\n",
        "g.add((ns.hasQSegment, RDFS.label, Literal(\"Has Quranic Segment\", lang=\"en\")))\n",
        "g.add((ns.hasQSegment, RDFS.label, Literal(\"Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ŸÖŸÇÿ∑ÿπ ŸÇÿ±ÿ¢ŸÜŸä\", lang=\"ar\")))\n",
        "\n",
        "g.add((isPartOfQ, RDF.type, OWL.ObjectProperty))\n",
        "g.add((isPartOfQ, RDFS.domain, ns.QuranChapter))\n",
        "g.add((isPartOfQ, RDFS.range, ns.Quran))#we need to edit it QuranChapter\n",
        "g.add((isPartOfQ, RDFS.label, Literal(\"Is Part Of\", lang=\"en\")))\n",
        "g.add((isPartOfQ, RDFS.label, Literal(\"ÿ¨ÿ≤ÿ° ŸÖŸÜ\", lang=\"ar\")))\n",
        "\n",
        "\n",
        "g.add((discussQuranTopics, RDF.type, OWL.ObjectProperty))\n",
        "g.add((discussQuranTopics, RDFS.domain, ns.Verse))#we need to edit it\n",
        "g.add((discussQuranTopics, RDFS.range, ns.QuranTopic))\n",
        "g.add((discussQuranTopics, RDFS.label, Literal(\"Discuss Quran Topics\", lang=\"en\")))\n",
        "g.add((discussQuranTopics, RDFS.label, Literal(\"ÿ™ŸÜÿßŸÇÿ¥ ŸÖŸàÿßÿ∂Ÿäÿπ ÿßŸÑŸÇÿ±ÿ¢ŸÜ\", lang=\"ar\")))\n",
        "\n",
        "\n",
        "g.add((ns.isPartOfVerse, RDF.type, OWL.ObjectProperty))\n",
        "g.add((ns.isPartOfVerse, RDFS.domain, ns.QuranicWord))\n",
        "g.add((ns.isPartOfVerse, RDFS.range, ns.Verse))\n",
        "g.add((ns.isPartOfVerse, RDFS.label, Literal(\"Is Part of Verse\", lang=\"en\")))\n",
        "g.add((ns.isPartOfVerse, RDFS.label, Literal(\"ÿ¨ÿ≤ÿ° ŸÖŸÜ ÿ¢Ÿäÿ©\", lang=\"ar\")))\n",
        "\n",
        "#Quran Data Properties\n",
        "# ===========================\n",
        "# Data Property: English Segment\n",
        "# ===========================\n",
        "g.add((ns.hasBuckwalterSegment, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((ns.hasBuckwalterSegment, RDFS.domain, ns.QuranicSegment))\n",
        "g.add((ns.hasBuckwalterSegment, RDFS.range, RDFS.Literal))\n",
        "g.add((ns.hasBuckwalterSegment, RDFS.label, Literal(\"Buckwalter Segment\", lang=\"en\")))\n",
        "g.add((ns.hasBuckwalterSegment, RDFS.label, Literal(\"ŸÖŸÇÿ∑ÿπ ÿ®ÿßŸÉŸàÿßŸÑÿ™ÿ±\", lang=\"ar\")))\n",
        "\n",
        "# ===========================\n",
        "# Data Property: POS (Part of Speech)\n",
        "# ===========================\n",
        "g.add((ns.hasPOS, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((ns.hasPOS, RDFS.domain, ns.QuranicSegment))\n",
        "g.add((ns.hasPOS, RDFS.range, XSD.string))\n",
        "g.add((ns.hasPOS, RDFS.label, Literal(\"Part of Speech\", lang=\"en\")))\n",
        "g.add((ns.hasPOS, RDFS.label, Literal(\"ÿßŸÑŸàÿ≥ŸÖ ÿßŸÑŸÜÿ≠ŸàŸä\", lang=\"ar\")))\n",
        "\n",
        "\n",
        "g.add((ns.isPartOfWord, RDF.type, RDF.Property))\n",
        "g.add((ns.isPartOfWord, RDFS.domain, ns.QuranicSegment))\n",
        "g.add((ns.isPartOfWord, RDFS.range, ns.QuranicWord))\n",
        "g.add((ns.isPartOfWord, RDFS.label, Literal(\"Is Part of Word\", lang=\"en\")))\n",
        "g.add((ns.isPartOfWord, RDFS.label, Literal(\"ÿ¨ÿ≤ÿ° ŸÖŸÜ ŸÉŸÑŸÖÿ©\", lang=\"ar\")))\n",
        "# Add inverse relationship\n",
        "g.add((ns.hasQSegment, OWL.inverseOf, ns.isPartOfWord))\n",
        "g.add((ns.hasQWord, OWL.inverseOf, ns.isPartOfVerse))\n",
        "\n",
        "\n",
        "# Jalalayn Property\n",
        "g.add((hasTafsirByJalalayn, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((hasTafsirByJalalayn, RDFS.domain, ns.Verse))\n",
        "g.add((hasTafsirByJalalayn, RDFS.range, RDFS.Literal))\n",
        "g.add((hasTafsirByJalalayn, RDFS.label, Literal(\"Has Tafsir By Jalalayn\", lang=\"en\")))\n",
        "g.add((hasTafsirByJalalayn, RDFS.label, Literal(\"ÿ™ŸÅÿ≥Ÿäÿ± ÿßŸÑÿ¨ŸÑÿßŸÑŸäŸÜ\", lang=\"ar\")))\n",
        "\n",
        "# Muyasser Property\n",
        "g.add((hasTafsirByMuyasser, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((hasTafsirByMuyasser, RDFS.domain, ns.Verse))\n",
        "g.add((hasTafsirByMuyasser, RDFS.range, RDFS.Literal))\n",
        "g.add((hasTafsirByMuyasser, RDFS.label, Literal(\"Has Tafsir by Muyasser\", lang=\"en\")))\n",
        "g.add((hasTafsirByMuyasser, RDFS.label, Literal(\"ÿ™ŸÅÿ≥Ÿäÿ± ÿßŸÑŸÖŸäÿ≥ÿ±\", lang=\"ar\")))\n",
        "\n",
        "#Quranic Concepts\n",
        "g.add((hasQuranicConcept, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((hasQuranicConcept, RDFS.domain, ns.Verse))\n",
        "g.add((hasQuranicConcept, RDFS.range, RDFS.Literal))\n",
        "g.add((hasQuranicConcept, RDFS.label, Literal(\"Has Concept\", lang=\"en\")))\n",
        "g.add((hasQuranicConcept, RDFS.label, Literal(\"ÿßŸÑŸÖŸÅŸáŸàŸÖ\", lang=\"ar\")))\n",
        "\n",
        "# Symmetric property: relatedTo\n",
        "relatedTo = ns.relatedTo\n",
        "g.add((relatedTo, RDF.type, OWL.ObjectProperty))\n",
        "g.add((relatedTo, RDF.type, OWL.SymmetricProperty))   # üîë make it symmetric\n",
        "#g.add((relatedTo, RDFS.domain, ns.QuranTopic))\n",
        "#g.add((relatedTo, RDFS.range, ns.HadithTopic))\n",
        "g.add((relatedTo, RDFS.label, Literal(\"Related To\", lang=\"en\")))\n",
        "g.add((relatedTo, RDFS.label, Literal(\"ŸÖÿ±ÿ™ÿ®ÿ∑ ÿ®ŸÄ\", lang=\"ar\")))\n",
        "\n",
        "# ===========================\n",
        "# Define Hadith object and Data properties\n",
        "# ===========================\n",
        "hasHChapter = ns.hasHChapter\n",
        "isPartOfH= ns.isPartOfH\n",
        "discussHadithTopic = ns.discussHadithTopic\n",
        "\n",
        "# ===========================\n",
        "#Hadith Object Properties\n",
        "# ===========================\n",
        "\n",
        "g.add((hasHChapter, RDF.type, OWL.ObjectProperty))\n",
        "g.add((hasHChapter, RDFS.domain, ns.HadithBook))\n",
        "g.add((hasHChapter, RDFS.range, ns.HadithChapter))\n",
        "g.add((hasHChapter, RDFS.label, Literal(\"Has chapter\", lang=\"en\")))\n",
        "g.add((hasHChapter, RDFS.label, Literal(\"Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ÿ®ÿßÿ®\", lang=\"ar\")))\n",
        "\n",
        "g.add((isPartOfH, RDF.type, OWL.ObjectProperty))\n",
        "g.add((isPartOfH, RDFS.domain, ns.HadithText))\n",
        "g.add((isPartOfH, RDFS.range, ns.HadithChapter))\n",
        "g.add((isPartOfH, RDFS.label, Literal(\"Is part of\", lang=\"en\")))\n",
        "g.add((isPartOfH, RDFS.label, Literal(\"ÿ¨ÿ≤ÿ° ŸÖŸÜ\", lang=\"ar\")))\n",
        "\n",
        "g.add((isPartOfH, RDF.type, OWL.ObjectProperty))\n",
        "g.add((isPartOfH, RDFS.domain, ns.HadithChapter))\n",
        "g.add((isPartOfH, RDFS.range, ns.HadithBook))\n",
        "g.add((isPartOfH, RDFS.label, Literal(\"Is part of\", lang=\"en\")))\n",
        "g.add((isPartOfH, RDFS.label, Literal(\"ÿ¨ÿ≤ÿ° ŸÖŸÜ\", lang=\"ar\")))\n",
        "\n",
        "g.add((discussHadithTopic, RDF.type, OWL.ObjectProperty))\n",
        "g.add((discussHadithTopic, RDFS.domain, ns.HadithText))\n",
        "g.add((discussHadithTopic, RDFS.range, ns.HadithTopic))\n",
        "g.add((discussHadithTopic, RDFS.label, Literal(\"Discuss Hadith Topics\", lang=\"en\")))\n",
        "g.add((discussHadithTopic, RDFS.label, Literal(\"ŸäŸÜÿßŸÇÿ¥ ŸÖŸàÿßÿ∂Ÿäÿπ ÿßŸÑÿ≠ÿØŸäÿ´\", lang=\"ar\")))\n",
        "\n",
        "# ===========================\n",
        "#Hadith Data Properties\n",
        "# ===========================\n",
        "\n",
        "hasIsnad = ns.hasIsnad\n",
        "hasMatn = ns.hasMatn\n",
        "hasGrade = ns.hasGrade\n",
        "\n",
        "# Isnad Property\n",
        "g.add((hasIsnad, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((hasIsnad, RDFS.domain, ns.HadithText))\n",
        "g.add((hasIsnad, RDFS.range, RDFS.Literal))\n",
        "g.add((hasIsnad, RDFS.label, Literal(\"English Isnad\", lang=\"en\")))\n",
        "g.add((hasIsnad, RDFS.label, Literal(\"ÿßŸÑŸÖÿ™ŸÜ ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\", lang=\"ar\")))\n",
        "\n",
        "# Matn Property\n",
        "g.add((hasMatn, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((hasMatn, RDFS.domain, ns.HadithText))\n",
        "g.add((hasMatn, RDFS.range, RDFS.Literal))\n",
        "g.add((hasMatn, RDFS.label, Literal(\"English Matn\", lang=\"en\")))\n",
        "g.add((hasMatn, RDFS.label, Literal(\"ÿßŸÑÿ•ÿ≥ŸÜÿßÿØ ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\", lang=\"ar\")))\n",
        "\n",
        "# Grade Property\n",
        "g.add((hasGrade, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((hasGrade, RDFS.domain, ns.HadithText))\n",
        "g.add((hasGrade, RDFS.range, RDFS.Literal))\n",
        "g.add((hasGrade, RDFS.label, Literal(\"English Grading\", lang=\"en\")))\n",
        "g.add((hasGrade, RDFS.label, Literal(\"ÿßŸÑÿ™ÿµŸÜŸäŸÅ ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\", lang=\"ar\")))\n",
        "\n",
        "\n",
        "# Define totalChapters Datatype Property\n",
        "totalChapters_prop = ns[\"totalChapters\"]\n",
        "g.add((totalChapters_prop, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((totalChapters_prop, RDFS.label, Literal(\"Total Chapters\", lang='en')))\n",
        "g.add((totalChapters_prop, RDFS.label, Literal(\"ÿ•ÿ¨ŸÖÿßŸÑŸä ÿßŸÑÿ£ÿ®Ÿàÿßÿ®\", lang='ar')))\n",
        "\n",
        "totalHadiths_prop = ns[\"totalHadiths\"]\n",
        "g.add((totalHadiths_prop, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((totalHadiths_prop, RDFS.label, Literal(\"Total Hadiths\", lang='en')))\n",
        "g.add((totalHadiths_prop, RDFS.label, Literal(\"ÿ•ÿ¨ŸÖÿßŸÑŸä ÿßŸÑÿ£ÿ≠ÿßÿØŸäÿ´\", lang='ar')))\n",
        "\n",
        "#for Quran, verses count\n",
        "totalVerses_prop = ns[\"totalVerses\"]\n",
        "g.add((totalVerses_prop, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((totalVerses_prop, RDFS.label, Literal(\"Total Verses\", lang='en')))\n",
        "g.add((totalVerses_prop, RDFS.label, Literal(\"ÿ•ÿ¨ŸÖÿßŸÑŸä ÿßŸÑÿ¢Ÿäÿßÿ™\", lang='ar')))\n",
        "\n",
        "# Non-related property\n",
        "#unrelatedTo = ns.unrelatedTo\n",
        "#g.add((unrelatedTo, RDF.type, OWL.ObjectProperty))\n",
        "#g.add((unrelatedTo, RDF.type, OWL.SymmetricProperty))   # ‚úÖ make it symmetric\n",
        "#g.add((unrelatedTo, RDFS.domain, ns.QuranTopic))\n",
        "#g.add((unrelatedTo, RDFS.range, ns.HadithTopic))\n",
        "#g.add((unrelatedTo, RDFS.label, Literal(\"Unrelated To\", lang=\"en\")))\n",
        "#g.add((unrelatedTo, RDFS.label, Literal(\"ÿ∫Ÿäÿ± ŸÖÿ±ÿ™ÿ®ÿ∑ ÿ®ŸÄ\", lang=\"ar\")))"
      ],
      "metadata": {
        "id": "7HJpnbzLhvN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Function to add Quran Data ===\n",
        "def add_qurand_to_graph(df1, g, ns):\n",
        "    quran_uri = URIRef(ns + \"Quran\")\n",
        "    g.add((quran_uri, RDF.type, ns.Quran))\n",
        "\n",
        "    for _, row in df1.iterrows():\n",
        "        chapter_id = URIRef(ns + row['Chapter_Index'])#(ns + f\"QChapter_{row['Chapter_ID']}\")\n",
        "        g.add((chapter_id, RDF.type, ns.QuranChapter))\n",
        "        g.add((chapter_id, RDFS.label, Literal(row['Chapter_English'], lang='en')))\n",
        "        g.add((chapter_id, RDFS.label, Literal(row['Chapter_Arabic'], lang='ar')))\n",
        "        g.add((chapter_id, ns.isPartOfQ, quran_uri))\n",
        "\n",
        "\n",
        "        verse_id = URIRef(ns+ row['Verse_ID'])\n",
        "        g.add((verse_id, RDF.type, ns.Verse))\n",
        "        g.add((verse_id, RDFS.label, Literal(row['Translation'], lang='en')))\n",
        "        g.add((verse_id, RDFS.label, Literal(row['Verse'], lang='ar')))\n",
        "        g.add((verse_id, ns.isPartOfQ, chapter_id))\n",
        "        g.add((verse_id, ns.hasTafsirByJalalayn, Literal(row[\"desc_ByJalalayn\"], lang=\"ar\")))\n",
        "\n",
        "       # Tafsir by Muyasser (data property: Literal)\n",
        "        g.add((verse_id, ns.hasTafsirByMuyasser, Literal(row[\"desc_ByMuyasser\"], lang=\"ar\")))\n",
        "        g.add((verse_id, ns.hasQuranicConcept, Literal(row[\"Concepts_E\"], lang=\"en\")))\n",
        "        g.add((verse_id, ns.hasQuranicConcept, Literal(row[\"Concepts_A\"], lang=\"ar\")))\n",
        "\n",
        "\n",
        "        if pd.notna(row.get('Topic_Index')):\n",
        "            topic_uri = URIRef(ns + row['Topic_Index'])\n",
        "            g.add((topic_uri, RDF.type, ns.QuranTopic))\n",
        "            if pd.notna(row.get('Topics_E')):\n",
        "                g.add((topic_uri, RDFS.label, Literal(row['Topics_E'], lang='en')))\n",
        "            if pd.notna(row.get('Topics_A')):\n",
        "                g.add((topic_uri, RDFS.label, Literal(row['Topics_A'], lang='ar')))\n",
        "            g.add((verse_id, ns.discussQuranTopics, topic_uri))"
      ],
      "metadata": {
        "id": "HL4hccMNhuub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Quran Data\n",
        "add_qurand_to_graph(df1, g, ns)"
      ],
      "metadata": {
        "id": "_NXacvtYoF88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Function to add Quranic Words (Dataset B) ===\n",
        "def add_words_to_graph(wordDF, g, ns):\n",
        "    for _, row in wordDF.iterrows():\n",
        "        word_id_str = str(row['word']).strip()\n",
        "        word_uri = URIRef(ns + word_id_str)\n",
        "\n",
        "        # parent Verse ID = first 2 parts of word ID\n",
        "        verse_id_str = \"-\".join(word_id_str.split(\"-\")[:2])\n",
        "        verse_uri = URIRef(ns + verse_id_str)\n",
        "\n",
        "        # add QuranicWord individual\n",
        "        g.add((word_uri, RDF.type, ns.QuranicWord))\n",
        "        g.add((word_uri, RDFS.label, Literal(str(row['wordArabic']).strip(), lang='ar')))\n",
        "\n",
        "        # link to verse\n",
        "        g.add((verse_uri, ns.hasQWord, word_uri))\n",
        "        g.add((word_uri, ns.isPartOfVerse, verse_uri))"
      ],
      "metadata": {
        "id": "19z2ms23nBL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CALL FUNCTION ---\n",
        "add_words_to_graph(wordDF, g, ns)"
      ],
      "metadata": {
        "id": "hqApFiElnBJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Function to add Quranic Segments (Dataset C) ===\n",
        "def add_segments_to_graph(segmdf, g, ns):\n",
        "    for _, row in segmdf.iterrows():\n",
        "        seg_id_str = str(row['ID']).strip()\n",
        "        seg_uri = URIRef(ns + seg_id_str)\n",
        "\n",
        "        # parent Word ID = first 3 parts\n",
        "        word_id_str = \"-\".join(seg_id_str.split(\"-\")[:3])\n",
        "        word_uri = URIRef(ns + word_id_str)\n",
        "\n",
        "        # add Segment individual\n",
        "        g.add((seg_uri, RDF.type, ns.QuranicSegment))\n",
        "        g.add((seg_uri, RDFS.label, Literal(str(row['seg']).strip(), lang='ar')))\n",
        "\n",
        "        # link to word\n",
        "        g.add((word_uri, ns.hasQSegment, seg_uri))\n",
        "        g.add((seg_uri, ns.isPartOfWord, word_uri))\n",
        "        g.add((seg_uri, ns.hasBuckwalterSegment, Literal(str(row['buck']).strip(), lang='en')))\n",
        "        # When adding actual values\n",
        "        g.add((seg_uri, ns.hasPOS, Literal(row[\"pos\"], datatype=XSD.string)))\n"
      ],
      "metadata": {
        "id": "XllOMcu2nBHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_segments_to_graph(segmdf, g, ns)"
      ],
      "metadata": {
        "id": "5ua43VFnnTCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map sheet names to HadithBook class names\n",
        "hadith_sheet_to_book = {\n",
        "    \"SB\": \"SahihAlBukhari\",\n",
        "    \"MUS\": \"SahihMuslim\",\n",
        "    \"ad\": \"SunanAbuDawood\",\n",
        "    \"TIR\": \"JamiAtTirmidhi\",\n",
        "    \"NES\": \"SunanAnNasai\",\n",
        "    \"im\": \"SunanIbnMajah\"\n",
        "}\n",
        "\n",
        "\n",
        "# === Function to add Hadith books ===\n",
        "def add_hadithd_book_to_graph(book_class_name, df, g, ns):\n",
        "    book_uri = ns[book_class_name]  # Refer to existing class URI\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        chapter_uri = URIRef(ns + str(row['Chapter_Index']))\n",
        "        g.add((chapter_uri, RDF.type, ns.HadithChapter))\n",
        "        g.add((chapter_uri, RDFS.label, Literal(row['Chapter_English'], lang='en')))\n",
        "        g.add((chapter_uri, RDFS.label, Literal(row['Chapter_Arabic'], lang='ar')))\n",
        "        g.add((chapter_uri, ns.isPartOfH, book_uri))\n",
        "\n",
        "        hadith_uri = URIRef(ns + str(row['Hadith_Index']))\n",
        "        g.add((hadith_uri, RDF.type, ns.HadithText))\n",
        "        g.add((hadith_uri, RDFS.label, Literal(row['English_Hadith'], lang='en')))\n",
        "        g.add((hadith_uri, RDFS.label, Literal(row['Arabic_Hadith'], lang='ar')))\n",
        "        g.add((hadith_uri, ns.isPartOfH, chapter_uri))\n",
        "\n",
        "        g.add((hadith_uri, ns.hasIsnad, Literal(row[\"English_Isnad\"], lang=\"en\")))\n",
        "        g.add((hadith_uri, ns.hasIsnad, Literal(row[\"Arabic_Isnad\"], lang=\"ar\")))\n",
        "\n",
        "        g.add((hadith_uri, ns.hasMatn, Literal(row[\"English_Matn\"], lang=\"en\")))\n",
        "        g.add((hadith_uri, ns.hasMatn, Literal(row[\"Arabic_Matn\"], lang=\"ar\")))\n",
        "\n",
        "        g.add((hadith_uri, ns.hasGrade, Literal(row[\"English_Grade\"], lang=\"en\")))\n",
        "        g.add((hadith_uri, ns.hasGrade, Literal(row[\"Arabic_Grade\"], lang=\"ar\")))\n",
        "\n",
        "        if pd.notna(row.get('Topic_Index')):\n",
        "            topic_uri = URIRef(ns + str(row['Topic_Index']))\n",
        "            g.add((topic_uri, RDF.type, ns.HadithTopic))\n",
        "            if pd.notna(row.get('English_Topic')):\n",
        "                g.add((topic_uri, RDFS.label, Literal(row['English_Topic'], lang='en')))\n",
        "            if pd.notna(row.get('Arabic_Topic')):\n",
        "                g.add((topic_uri, RDFS.label, Literal(row['Arabic_Topic'], lang='ar')))\n",
        "            g.add((hadith_uri, ns.discussHadithTopic, topic_uri))"
      ],
      "metadata": {
        "id": "Nm15889_nS3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Excel file\n",
        "#The correct code to link the Hadith chpters and teaching to the predefined classes names such as Sahih Albukhari book.\n",
        "\n",
        "excel_file = pd.ExcelFile(\"file-name.xlsx\")#the main file"
      ],
      "metadata": {
        "id": "SXPyrDfZnStL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Track chapter and hadith counts\n",
        "chapter_counts = {}\n",
        "hadith_counts = {}\n",
        "\n",
        "# Process Hadith Data & Count Chapters & Hadiths\n",
        "for sheet_name in excel_file.sheet_names:\n",
        "    if sheet_name in hadith_sheet_to_book:\n",
        "        df = excel_file.parse(sheet_name)\n",
        "        if not df.empty:\n",
        "            mapped_book = hadith_sheet_to_book[sheet_name]\n",
        "            add_hadithd_book_to_graph(mapped_book, df, g, ns)\n",
        "\n",
        "            # Count unique chapters and hadiths per book\n",
        "            chapter_counts[mapped_book] = df['Chapter_Index'].nunique()\n",
        "            hadith_counts[mapped_book] = df['Hadith_Index'].nunique()\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Skipped unknown sheet: {sheet_name}\")\n",
        "\n",
        "# Add totalChapters and totalHadiths properties to HadithBook classes\n",
        "for book_name in chapter_counts:\n",
        "    g.add((ns[book_name], ns.totalChapters, Literal(chapter_counts[book_name])))\n",
        "    g.add((ns[book_name], ns.totalHadiths, Literal(hadith_counts[book_name])))"
      ],
      "metadata": {
        "id": "sJSSU4Y8nSkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Count total verses per Surah using Chapter_Index as Surah URI\n",
        "verses_per_surah = df1.groupby('Chapter_Index')['Verse_ID'].count().to_dict()\n",
        "\n",
        "for chapter_index, total_verses in verses_per_surah.items():\n",
        "    surah_uri = URIRef(ns + str(chapter_index))\n",
        "    g.add((surah_uri, ns.totalVerses, Literal(total_verses)))"
      ],
      "metadata": {
        "id": "-5awE03YnSbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load datasets\n",
        "df_related = pd.read_excel(\"file-name.xlsx\")\n",
        "#df_unrelated = pd.read_excel(\"file-name.xlsx\")\n",
        "\n",
        "# --- Add related topics --- we link them based on their IDs\n",
        "for _, row in df_related.iterrows():\n",
        "    if pd.notna(row[\"QuranTopic_ID\"]) and pd.notna(row[\"HadithTopic_ID\"]):\n",
        "        q_topic = URIRef(ns + row[\"QuranTopic_ID\"])\n",
        "        h_topic = URIRef(ns + row[\"HadithTopic_ID\"])\n",
        "\n",
        "        # Add symmetric relation\n",
        "        g.add((q_topic, relatedTo, h_topic))\n",
        "        # Since it's symmetric, a reasoner (HermiT, Pellet) will infer (h_topic ‚Üí q_topic)\n",
        "\n",
        "# --- Add unrelated topics --- Not Included\n",
        "#for _, row in df_unrelated.iterrows():\n",
        "#    if pd.notna(row[\"QuranTopic_ID\"]) and pd.notna(row[\"HadithTopic_ID\"]):\n",
        "#        q_topic = URIRef(ns + row[\"QuranTopic_ID\"])\n",
        "#        h_topic = URIRef(ns + row[\"HadithTopic_ID\"])\n",
        "\n",
        "#        g.add((q_topic, unrelatedTo, h_topic))\n",
        "\n"
      ],
      "metadata": {
        "id": "iKS5Tl8CnSOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Serialize the final ontology\n",
        "g.serialize(\"Final_Islamic_Ontology_Quran_Hadith.ttl\", format=\"turtle\")"
      ],
      "metadata": {
        "id": "9s4_zz6DowpR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}