{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQGEr+Z8lyIXdQBzEsovBi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibtisam-a/Integrated-Islamic-Ontology/blob/main/Automatic_Ontology_Integration_of_Islamic_Resources.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AI for Automated Ontology Integration of Islamic Resources (Qur'an and Hadith)**"
      ],
      "metadata": {
        "id": "jSk0kNfTFWZL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEYDNAJjFQPj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing required libraries\n"
      ],
      "metadata": {
        "id": "JwfJ4SX_F71L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas rdflib openpyxl"
      ],
      "metadata": {
        "id": "7Z4iQWfiFRlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the Datasets"
      ],
      "metadata": {
        "id": "yhPIEYwAGBGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#Hadith dataset\n",
        "# Load the Excel file\n",
        "file_path = 'yourFileName.xlsx'  # Replace with your file path (Quran)\n",
        "df = pd.read_excel(file_path)\n",
        "# Show the first few rows\n",
        "#print(df.head())\n"
      ],
      "metadata": {
        "id": "kHIi3yCtFRi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#Quran dataset\n",
        "# Load the Excel file\n",
        "file_path = 'yourFileName.xlsx'   # Replace with your other file path (Hadith)\n",
        "df1 = pd.read_excel(file_path)"
      ],
      "metadata": {
        "id": "p0EzhZF0FRgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building the Ontology**"
      ],
      "metadata": {
        "id": "43mUDRKWGk8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------\n",
        "# Step 1: Imports & Graph Initialization\n",
        "# ----------------------\n",
        "\n",
        "from rdflib import Graph, Namespace, RDF, RDFS, OWL, Literal\n",
        "\n",
        "# Create RDF graph\n",
        "g = Graph()\n",
        "\n",
        "# Define namespace\n",
        "ns = Namespace(\"http://IslamicOntology.org/Resources#\")\n",
        "g.bind(\"ibs\", ns)\n",
        "g.bind(\"rdfs\", RDFS)\n",
        "\n",
        "# ----------------------\n",
        "# Step 2: Define Classes\n",
        "# ----------------------\n",
        "\n",
        "classes = {\n",
        "    \"IslamicResources\": None, #(None, \"Islamic Resources\", \"ÿßŸÑŸÜÿµŸàÿµ ÿßŸÑÿ•ÿ≥ŸÑÿßŸÖŸäÿ©\"),#IslamicTexts    ÿßŸÑŸÜÿµŸàÿµ\n",
        "    \"HadithBook\": \"IslamicResources\", #  (\"IslamicResources\", \"Hadith Book\", \"ŸÉÿ™ÿ® ÿßŸÑÿ≠ÿØŸäÿ´\"),\n",
        "    \"Quran\": \"IslamicResources\", # (\"IslamicResources\", \"Quran\", \"ÿßŸÑŸÇÿ±ÿ¢ŸÜ\"),\n",
        "    \"QuranChapter\": \"IslamicResources\", # (\"IslamicResources\", \"Chapter\",  \"ÿßŸÑÿ≥Ÿàÿ±ÿ©\"),\n",
        "    \"Verse\": \"IslamicResources\", # (\"IslamicResources\", \"Verse\",  \"ÿßŸÑÿ¢Ÿäÿ©\"),\n",
        "    \"QuranicWord\": \"IslamicResources\",\n",
        "    \"QuranicSegment\":\"IslamicResources\",\n",
        "    \"QuranTopic\": None, #(\"IslamicResources\", \"QTopic\",  \"ŸÖŸàÿ∂Ÿàÿπ ÿßŸÑŸÇÿ±ÿ¢ŸÜ\"),\n",
        "    \"HadithChapter\": \"IslamicResources\", #(\"IslamicTexts\", \"Hadith Chapter\", \"ÿ®ÿßÿ® ÿßŸÑÿ≠ÿØŸäÿ´\"),\n",
        "    \"HadithText\": \"IslamicResources\", #(\"IslamicTexts\", \"Hadith Text\", \"ŸÜÿµ ÿßŸÑÿ≠ÿØŸäÿ´\"),\n",
        "    \"HadithTopic\": None, #(\"IslamicTexts\", \"Hadith Topic\", \"ŸÖŸàÿ∂Ÿàÿπ ÿßŸÑÿ≠ÿØŸäÿ´\")\n",
        "}\n",
        "# Class labels in English and Arabic\n",
        "class_labels = {\n",
        "    \"IslamicResources\": {\"en\": \"Islamic Resources\", \"ar\": \"ÿßŸÑŸÜÿµŸàÿµ ÿßŸÑÿ•ÿ≥ŸÑÿßŸÖŸäÿ©\"},\n",
        "    \"Quran\": {\"en\": \"Quran\", \"ar\": \"ÿßŸÑŸÇÿ±ÿ¢ŸÜ\"},\n",
        "    \"HadithBook\": {\"en\":\"Hadith Book\", \"ar\": \"ŸÉÿ™ÿßÿ® ÿßŸÑÿ≠ÿØŸäÿ´\"},\n",
        "    \"QuranChapter\": {\"en\": \"Quran Chapter\", \"ar\": \"ÿ≥Ÿàÿ±ÿ©\"},\n",
        "    \"Verse\": {\"en\": \"Quran Verse\", \"ar\": \"ÿ¢Ÿäÿ©\"},\n",
        "    \"QuranicWord\": {\"en\": \"Quran Word\", \"ar\": \"ŸÉŸÑŸÖÿ© ŸÇÿ±ÿ¢ŸÜŸäÿ©\"},\n",
        "    \"QuraniSegment\": {\"en\": \"Quran Segment\", \"ar\": \"ŸÖŸÇÿ∑ÿπ ŸÇÿ±ÿ¢ŸÜŸä\"},\n",
        "    \"QuranTopic\": {\"en\": \"Quran Topic\", \"ar\": \"ŸÖŸàÿ∂Ÿàÿπ ŸÇÿ±ÿ¢ŸÜŸä\"},\n",
        "    \"HadithChapter\": {\"en\": \"Hadith Chapter\", \"ar\": \"ÿ®ÿßÿ® ÿßŸÑÿ≠ÿØŸäÿ´\"},\n",
        "    \"HadithText\": {\"en\": \"Hadith Text\", \"ar\": \"ŸÜÿµ ÿßŸÑÿ≠ÿØŸäÿ´\"},\n",
        "    \"HadithTopic\": {\"en\":\"Hadith Topic\", \"ar\": \"ŸÖŸàÿ∂Ÿàÿπ ÿßŸÑÿ≠ÿØŸäÿ´\"},\n",
        "}\n",
        "\n",
        "# Create classes, subclass relationships, and labels\n",
        "for cls, parent in classes.items():\n",
        "    cls_uri = ns[cls]\n",
        "    g.add((cls_uri, RDF.type, OWL.Class))\n",
        "    if parent:\n",
        "        parent_uri = ns[parent]\n",
        "        g.add((cls_uri, RDFS.subClassOf, parent_uri))\n",
        "\n",
        "    # Add English and Arabic labels if available\n",
        "    if cls in class_labels:\n",
        "        labels = class_labels[cls]\n",
        "        g.add((cls_uri, RDFS.label, Literal(labels['en'], lang='en')))\n",
        "        g.add((cls_uri, RDFS.label, Literal(labels['ar'], lang='ar')))\n",
        "\n",
        "        # -------------------------\n",
        "# Hadith books INDIVIDUALS (not classes)\n",
        "# -------------------------\n",
        "hadith_books_individuals = {\n",
        "    \"SahihAlBukhari\": {\"en\": \"Sahih Al-Bukhari\", \"ar\": \"ÿµÿ≠Ÿäÿ≠ ÿßŸÑÿ®ÿÆÿßÿ±Ÿä\"},\n",
        "    \"SahihMuslim\": {\"en\": \"Sahih Muslim\", \"ar\": \"ÿµÿ≠Ÿäÿ≠ ŸÖÿ≥ŸÑŸÖ\"},\n",
        "    \"SunanAbuDawood\": {\"en\": \"Sunan Abu Dawood\", \"ar\": \"ÿ≥ŸÜŸÜ ÿ£ÿ®Ÿä ÿØÿßŸàÿØ\"},\n",
        "    \"JamiAtTirmidhi\": {\"en\": \"Jami' At-Tirmidhi\", \"ar\": \"ÿ¨ÿßŸÖÿπ ÿßŸÑÿ™ÿ±ŸÖÿ∞Ÿä\"},\n",
        "    \"SunanAnNasai\": {\"en\": \"Sunan An-Nasa'i\", \"ar\": \"ÿ≥ŸÜŸÜ ÿßŸÑŸÜÿ≥ÿßÿ¶Ÿä\"},\n",
        "    \"SunanIbnMajah\": {\"en\": \"Sunan Ibn Majah\", \"ar\": \"ÿ≥ŸÜŸÜ ÿßÿ®ŸÜ ŸÖÿßÿ¨Ÿá\"},\n",
        "}\n",
        "\n",
        "for ind, lbl in hadith_books_individuals.items():\n",
        "    ind_uri = ns[ind]\n",
        "    g.add((ind_uri, RDF.type, ns[\"HadithBook\"]))\n",
        "    g.add((ind_uri, RDFS.label, Literal(lbl[\"en\"], lang=\"en\")))\n",
        "    g.add((ind_uri, RDFS.label, Literal(lbl[\"ar\"], lang=\"ar\")))\n"
      ],
      "metadata": {
        "id": "3Tu2Ve-EFRfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "## Step 3:  Define Quran and Hadith object properties\n",
        "# ----------------------\n",
        "\n",
        "from rdflib.namespace import XSD\n",
        "\n",
        "hasChapter = ns.hasChapter\n",
        "isPartOf= ns.isPartOf\n",
        "discussHadithTopics = ns.discussHadithTopics\n",
        "\n",
        "g.add((hasChapter, RDF.type, OWL.ObjectProperty))\n",
        "g.add((hasChapter, RDFS.domain, ns.HadithBook))\n",
        "g.add((hasChapter, RDFS.range, ns.HadithChapter))\n",
        "g.add((hasChapter, RDFS.label, Literal(\"Has chapter\", lang=\"en\")))\n",
        "g.add((hasChapter, RDFS.label, Literal(\"Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ÿ®ÿßÿ®\", lang=\"ar\")))\n",
        "\n",
        "g.add((isPartOf, RDF.type, OWL.ObjectProperty))\n",
        "g.add((isPartOf, RDFS.domain, ns[\"IslamicResources\"]))\n",
        "g.add((isPartOf, RDFS.range,  ns[\"IslamicResources\"]))\n",
        "g.add((isPartOf, RDFS.label, Literal(\"is part of\", lang=\"en\")))\n",
        "g.add((isPartOf, RDFS.label, Literal(\"ÿ¨ÿ≤ÿ° ŸÖŸÜ\", lang=\"ar\")))\n",
        "\n",
        "\n",
        "g.add((discussHadithTopics, RDF.type, OWL.ObjectProperty))\n",
        "g.add((discussHadithTopics, RDFS.domain, ns.HadithText))\n",
        "g.add((discussHadithTopics, RDFS.range, ns.HadithTopic))\n",
        "g.add((discussHadithTopics, RDFS.label, Literal(\"Discuss Hadith Topics\", lang=\"en\")))\n",
        "g.add((discussHadithTopics, RDFS.label, Literal(\"ŸäŸÜÿßŸÇÿ¥ ŸÖŸàÿßÿ∂Ÿäÿπ ÿßŸÑÿ≠ÿØŸäÿ´\", lang=\"ar\")))\n",
        "\n",
        "# Define object property isPartOf\n",
        "\n",
        "discussQuranTopics = ns.discussQuranTopics\n",
        "hasQWord = ns.hasQWord\n",
        "hasQSegment = ns.hasQSegment\n",
        "hasBuckwalterSegment = ns.hasBuckwalterSegment\n",
        "hasPOS = ns.hasPOS\n",
        "\n",
        "\n",
        "# hasWord: Verse ‚Üí Word\n",
        "g.add((ns.hasQWord, RDF.type, OWL.ObjectProperty))\n",
        "g.add((ns.hasQWord, RDFS.domain, ns.Verse))\n",
        "g.add((ns.hasQWord, RDFS.range, ns.QuranicWord))\n",
        "g.add((ns.hasQWord, RDFS.label, Literal(\"Has Quranic Word\", lang=\"en\")))\n",
        "g.add((ns.hasQWord, RDFS.label, Literal(\"Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ŸÉŸÑŸÖÿ© ŸÇÿ±ÿ¢ŸÜŸäÿ©\", lang=\"ar\")))\n",
        "\n",
        "# hasSegment: Word ‚Üí Segment\n",
        "g.add((ns.hasQSegment, RDF.type, OWL.ObjectProperty))#\"QuranicSegmen\n",
        "g.add((ns.hasQSegment, RDFS.domain, ns.QuranicWord))\n",
        "g.add((ns.hasQSegment, RDFS.range, ns.QuranicSegment))\n",
        "g.add((ns.hasQSegment, RDFS.label, Literal(\"Has Quranic Segment\", lang=\"en\")))\n",
        "g.add((ns.hasQSegment, RDFS.label, Literal(\"Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ŸÖŸÇÿ∑ÿπ ŸÇÿ±ÿ¢ŸÜŸä\", lang=\"ar\")))\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# Data Property: English Segment\n",
        "# ===========================\n",
        "g.add((ns.hasBuckwalterSegment, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((ns.hasBuckwalterSegment, RDFS.domain, ns.QuranicSegment))\n",
        "g.add((ns.hasBuckwalterSegment, RDFS.range, RDFS.Literal))\n",
        "g.add((ns.hasBuckwalterSegment, RDFS.label, Literal(\"Buckwalter Segment\", lang=\"en\")))\n",
        "g.add((ns.hasBuckwalterSegment, RDFS.label, Literal(\"ŸÖŸÇÿ∑ÿπ ÿ®ÿßŸÉŸàÿßŸÑÿ™ÿ±\", lang=\"ar\")))\n",
        "\n",
        "# ===========================\n",
        "# Data Property: POS (Part of Speech)\n",
        "# ===========================\n",
        "g.add((ns.hasPOS, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((ns.hasPOS, RDFS.domain, ns.QuranicSegment))\n",
        "g.add((ns.hasPOS, RDFS.range, XSD.string))\n",
        "g.add((ns.hasPOS, RDFS.label, Literal(\"Part of Speech\", lang=\"en\")))\n",
        "g.add((ns.hasPOS, RDFS.label, Literal(\"ÿßŸÑŸàÿ≥ŸÖ ÿßŸÑŸÜÿ≠ŸàŸä\", lang=\"ar\")))\n",
        "\n",
        "g.add((discussQuranTopics, RDF.type, OWL.ObjectProperty))\n",
        "g.add((discussQuranTopics, RDFS.domain, ns.Verse))#we need to edit it\n",
        "g.add((discussQuranTopics, RDFS.range, ns.QuranTopic))\n",
        "g.add((discussQuranTopics, RDFS.label, Literal(\"Discuss Quran Topics\", lang=\"en\")))\n",
        "g.add((discussQuranTopics, RDFS.label, Literal(\"ÿ™ŸÜÿßŸÇÿ¥ ŸÖŸàÿßÿ∂Ÿäÿπ ÿßŸÑŸÇÿ±ÿ¢ŸÜ\", lang=\"ar\")))\n",
        "\n",
        "\n",
        "# Symmetric property: relatedTo\n",
        "relatedTo = ns.relatedTo\n",
        "g.add((relatedTo, RDF.type, OWL.ObjectProperty))\n",
        "g.add((relatedTo, RDF.type, OWL.SymmetricProperty))   # üîë make it symmetric\n",
        "g.add((relatedTo, RDFS.domain, ns.QuranTopic))\n",
        "g.add((relatedTo, RDFS.range, ns.HadithTopic))\n",
        "g.add((relatedTo, RDFS.label, Literal(\"Related To\", lang=\"en\")))\n",
        "g.add((relatedTo, RDFS.label, Literal(\"ŸÖÿ±ÿ™ÿ®ÿ∑ ÿ®ŸÄ\", lang=\"ar\")))\n",
        "\n",
        "hasIsnad = ns.hasIsnad\n",
        "hasMatn = ns.hasMatn\n",
        "hasGrade = ns.hasGrade\n",
        "\n",
        "# Isnad Property\n",
        "g.add((hasIsnad, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((hasIsnad, RDFS.domain, ns.HadithText))\n",
        "g.add((hasIsnad, RDFS.range, RDFS.Literal))\n",
        "g.add((hasIsnad, RDFS.label, Literal(\"English Isnad\", lang=\"en\")))\n",
        "g.add((hasIsnad, RDFS.label, Literal(\"ÿßŸÑŸÖÿ™ŸÜ ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\", lang=\"ar\")))\n",
        "\n",
        "# Matn Property\n",
        "g.add((hasMatn, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((hasMatn, RDFS.domain, ns.HadithText))\n",
        "g.add((hasMatn, RDFS.range, RDFS.Literal))\n",
        "g.add((hasMatn, RDFS.label, Literal(\"English Matn\", lang=\"en\")))\n",
        "g.add((hasMatn, RDFS.label, Literal(\"ÿßŸÑÿ•ÿ≥ŸÜÿßÿØ ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\", lang=\"ar\")))\n",
        "\n",
        "# Grade Property\n",
        "g.add((hasGrade, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((hasGrade, RDFS.domain, ns.HadithText))\n",
        "g.add((hasGrade, RDFS.range, RDFS.Literal))\n",
        "g.add((hasGrade, RDFS.label, Literal(\"English Grading\", lang=\"en\")))\n",
        "g.add((hasGrade, RDFS.label, Literal(\"ÿßŸÑÿ™ÿµŸÜŸäŸÅ ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\", lang=\"ar\")))\n",
        "\n",
        "\n",
        "hasTafsirByJalalayn = ns.hasTafsirByJalalayn\n",
        "hasTafsirByMuyasser = ns.hasTafsirByMuyasser\n",
        "hasQuranicConcept = ns.hasQuranicConcept\n",
        "\n",
        "# Jalalayn Property\n",
        "g.add((hasTafsirByJalalayn, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((hasTafsirByJalalayn, RDFS.domain, ns.Verse))\n",
        "g.add((hasTafsirByJalalayn, RDFS.range, RDFS.Literal))\n",
        "g.add((hasTafsirByJalalayn, RDFS.label, Literal(\"Has Tafsir By Jalalayn\", lang=\"en\")))\n",
        "g.add((hasTafsirByJalalayn, RDFS.label, Literal(\"ÿ™ŸÅÿ≥Ÿäÿ± ÿßŸÑÿ¨ŸÑÿßŸÑŸäŸÜ\", lang=\"ar\")))\n",
        "\n",
        "# Muyasser Property\n",
        "g.add((hasTafsirByMuyasser, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((hasTafsirByMuyasser, RDFS.domain, ns.Verse))\n",
        "g.add((hasTafsirByMuyasser, RDFS.range, RDFS.Literal))\n",
        "g.add((hasTafsirByMuyasser, RDFS.label, Literal(\"Has Tafsir by Muyasser\", lang=\"en\")))\n",
        "g.add((hasTafsirByMuyasser, RDFS.label, Literal(\"ÿ™ŸÅÿ≥Ÿäÿ± ÿßŸÑŸÖŸäÿ≥ÿ±\", lang=\"ar\")))\n",
        "\n",
        "#Quranic Concepts\n",
        "g.add((hasQuranicConcept, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((hasQuranicConcept, RDFS.domain, ns.Verse))\n",
        "g.add((hasQuranicConcept, RDFS.range, RDFS.Literal))\n",
        "g.add((hasQuranicConcept, RDFS.label, Literal(\"Has Concept\", lang=\"en\")))\n",
        "g.add((hasQuranicConcept, RDFS.label, Literal(\"ÿßŸÑŸÖŸÅŸáŸàŸÖ\", lang=\"ar\")))\n",
        "\n",
        "totalChapters_prop = ns[\"totalChapters\"]\n",
        "g.add((totalChapters_prop, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((totalChapters_prop, RDFS.label, Literal(\"Total Chapters\", lang='en')))\n",
        "g.add((totalChapters_prop, RDFS.label, Literal(\"ÿ•ÿ¨ŸÖÿßŸÑŸä ÿßŸÑÿ£ÿ®Ÿàÿßÿ®\", lang='ar')))\n",
        "\n",
        "totalHadiths_prop = ns[\"totalHadiths\"]\n",
        "g.add((totalHadiths_prop, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((totalHadiths_prop, RDFS.label, Literal(\"Total Hadiths\", lang='en')))\n",
        "g.add((totalHadiths_prop, RDFS.label, Literal(\"ÿ•ÿ¨ŸÖÿßŸÑŸä ÿßŸÑÿ£ÿ≠ÿßÿØŸäÿ´\", lang='ar')))\n",
        "\n",
        "#for Quran, verses count\n",
        "totalVerses_prop = ns[\"totalVerses\"]\n",
        "g.add((totalVerses_prop, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((totalVerses_prop, RDFS.label, Literal(\"Total Verses\", lang='en')))\n",
        "g.add((totalVerses_prop, RDFS.label, Literal(\"ÿ•ÿ¨ŸÖÿßŸÑŸä ÿßŸÑÿ¢Ÿäÿßÿ™\", lang='ar')))\n",
        "\n",
        "# Non-related property (not used in this work)\n",
        "#unrelatedTo = ns.unrelatedTo\n",
        "#g.add((unrelatedTo, RDF.type, OWL.ObjectProperty))\n",
        "#g.add((unrelatedTo, RDF.type, OWL.SymmetricProperty))   # ‚úÖ make it symmetric\n",
        "#g.add((unrelatedTo, RDFS.domain, ns.QuranTopic))\n",
        "#g.add((unrelatedTo, RDFS.range, ns.HadithTopic))\n",
        "#g.add((unrelatedTo, RDFS.label, Literal(\"Unrelated To\", lang=\"en\")))\n",
        "#g.add((unrelatedTo, RDFS.label, Literal(\"ÿ∫Ÿäÿ± ŸÖÿ±ÿ™ÿ®ÿ∑ ÿ®ŸÄ\", lang=\"ar\")))"
      ],
      "metadata": {
        "id": "mQQKEHWOFRcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 4: OWL Restrictions (reviewer-proof)\n",
        "#    Core: someValuesFrom\n",
        "# -------------------------\n",
        "def some_values_restriction(prop, filler):\n",
        "    r = BNode()\n",
        "    g.add((r, RDF.type, OWL.Restriction))\n",
        "    g.add((r, OWL.onProperty, prop))\n",
        "    g.add((r, OWL.someValuesFrom, filler))\n",
        "    return r\n",
        "\n",
        "# --- Quran structure ---\n",
        "# QuranChapter ‚äë ‚àÉ isPartOf . Quran\n",
        "g.add((ns[\"QuranChapter\"], RDFS.subClassOf, some_values_restriction(isPartOf, ns[\"Quran\"])))\n",
        "\n",
        "# Verse ‚äë ‚àÉ isPartOf . QuranChapter\n",
        "g.add((ns[\"Verse\"], RDFS.subClassOf, some_values_restriction(isPartOf, ns[\"QuranChapter\"])))\n",
        "\n",
        "# QuranicWord ‚äë ‚àÉ isPartOf . Verse\n",
        "g.add((ns[\"QuranicWord\"], RDFS.subClassOf, some_values_restriction(isPartOf, ns[\"Verse\"])))\n",
        "\n",
        "# QuranicSegment ‚äë ‚àÉ isPartOf . Verse  (you can change to QuranChapter if you prefer)\n",
        "g.add((ns[\"QuranicSegment\"], RDFS.subClassOf, some_values_restriction(isPartOf, ns[\"QuranicWord\"])))\n",
        "\n",
        "\n",
        "\n",
        "# --- Hadith structure ---\n",
        "# HadithChapter ‚äë ‚àÉ isPartOf . HadithBook\n",
        "g.add((ns[\"HadithChapter\"], RDFS.subClassOf, some_values_restriction(isPartOf, ns[\"HadithBook\"])))\n",
        "\n",
        "# HadithText ‚äë ‚àÉ isPartOf . HadithChapter\n",
        "g.add((ns[\"HadithText\"], RDFS.subClassOf, some_values_restriction(isPartOf, ns[\"HadithChapter\"])))\n",
        "\n",
        "\n",
        "# --- Disjointness (quality control) ---\n",
        "# Prevent mixing Quran structure classes with Hadith structure classes\n",
        "g.add((ns[\"QuranChapter\"], OWL.disjointWith, ns[\"HadithChapter\"]))\n",
        "g.add((ns[\"Verse\"], OWL.disjointWith, ns[\"HadithText\"]))\n",
        "\n"
      ],
      "metadata": {
        "id": "qo875n6sFRak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "#Step 5: Function to add Quran Data\n",
        "# -------------------------\n",
        "def add_qurand_to_graph(df1, g, ns):\n",
        "    quran_uri = URIRef(ns + \"Quran\")\n",
        "    g.add((quran_uri, RDF.type, ns.Quran))\n",
        "\n",
        "    for _, row in df1.iterrows():\n",
        "        chapter_id = URIRef(ns + row['Chapter_Index'])#(ns + f\"QChapter_{row['Chapter_ID']}\")\n",
        "        g.add((chapter_id, RDF.type, ns.QuranChapter))\n",
        "        g.add((chapter_id, RDFS.label, Literal(row['Chapter_English'], lang='en')))\n",
        "        g.add((chapter_id, RDFS.label, Literal(row['Chapter_Arabic'], lang='ar')))\n",
        "        #surah_uri = URIRef(ns + row['Chapter_Index'])\n",
        "        #graph.add((surah_uri, RDF.type, ns.Surah))\n",
        "       # graph.add((surah_uri, RDFS.label, Literal(row['Chapter_English'], lang='en')))\n",
        "       # graph.add((surah_uri, RDFS.label, Literal(row['Chapter_Arabic'], lang='ar')))\n",
        "        g.add((chapter_id, ns.isPartOf, quran_uri))\n",
        "\n",
        "\n",
        "        verse_id = URIRef(ns+ row['Verse_ID'])\n",
        "        g.add((verse_id, RDF.type, ns.Verse))\n",
        "        g.add((verse_id, RDFS.label, Literal(row['Translation'], lang='en')))\n",
        "        g.add((verse_id, RDFS.label, Literal(row['Verse'], lang='ar')))\n",
        "        g.add((verse_id, ns.isPartOf, chapter_id))   # ‚úÖ fix here!\n",
        "        #ayah_uri = URIRef(ns+ row['Verse_ID'])\n",
        "        #g.add((verse_id, ns.hasQWord, word_uri))\n",
        "        #graph.add((ayah_uri, RDF.type, ns.Ayah))\n",
        "        #graph.add((ayah_uri, RDFS.label, Literal(row['Translation'], lang='en')))\n",
        "        #graph.add((ayah_uri, RDFS.label, Literal(row['Verse'], lang='ar')))\n",
        "        g.add((verse_id, ns.hasTafsirByJalalayn, Literal(row[\"desc_ByJalalayn\"], lang=\"ar\")))\n",
        "    # Tafsir by Muyasser (data property: Literal)\n",
        "        g.add((verse_id, ns.hasTafsirByMuyasser, Literal(row[\"desc_ByMuyasser\"], lang=\"ar\")))\n",
        "        g.add((verse_id, ns.hasQuranicConcept, Literal(row[\"Concepts_E\"], lang=\"en\")))\n",
        "        g.add((verse_id, ns.hasQuranicConcept, Literal(row[\"Concepts_A\"], lang=\"ar\")))\n",
        "\n",
        "        #graph.add((ayah_uri, ns.isPartOfQ, surah_uri))\n",
        "        #g.add((ayah_uri, ns.hasTafsirByMuyasser, Literal(row[\"desc_ByMuyasser\"], lang=\"ar\")))\n",
        "        #g.add((ayah_uri, ns.hasTafsirByJalalayn, Literal(row[\"desc_ByJalalayn\"], lang=\"ar\")))\n",
        "        #g.add((ayah_uri, ns.hasQuranicConcept, Literal(row[\"Concepts_E\"], lang=\"en\")))\n",
        "        #g.add((ayah_uri, ns.hasQuranicConcept, Literal(row[\"Concepts_A\"], lang=\"ar\")))\n",
        "\n",
        "        if pd.notna(row.get('Topic_Index')):\n",
        "            topic_uri = URIRef(ns + row['Topic_Index'])\n",
        "            g.add((topic_uri, RDF.type, ns.QuranTopic))\n",
        "            if pd.notna(row.get('Topics_E')):\n",
        "                g.add((topic_uri, RDFS.label, Literal(row['Topics_E'], lang='en')))\n",
        "            if pd.notna(row.get('Topics_A')):\n",
        "                g.add((topic_uri, RDFS.label, Literal(row['Topics_A'], lang='ar')))\n",
        "            g.add((verse_id, ns.discussQuranTopics, topic_uri)) # I could change it to discussVerseTopic\n",
        "\n"
      ],
      "metadata": {
        "id": "hJ6v_BvDH20s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Quran Data\n",
        "add_qurand_to_graph(df1, g, ns)"
      ],
      "metadata": {
        "id": "MomceVRZIGPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 6: Function to add Words (based on your dataset)\n",
        "# -------------------------\n",
        "\n",
        "def add_words_to_graph(wordDF, g, ns):\n",
        "    for _, row in wordDF.iterrows():\n",
        "        word_id_str = str(row['word']).strip()\n",
        "        word_uri = URIRef(ns + word_id_str)\n",
        "\n",
        "        # parent Verse ID = first 2 parts of word ID\n",
        "        verse_id_str = \"-\".join(word_id_str.split(\"-\")[:2])\n",
        "        verse_uri = URIRef(ns + verse_id_str)\n",
        "\n",
        "        # add QuranicWord individual\n",
        "        g.add((word_uri, RDF.type, ns.QuranicWord))\n",
        "        g.add((word_uri, RDFS.label, Literal(str(row['wordArabic']).strip(), lang='ar')))\n",
        "\n",
        "        # link to verse\n",
        "        g.add((verse_uri, ns.hasQWord, word_uri))\n",
        "        g.add((word_uri, ns.isPartOf, verse_uri))"
      ],
      "metadata": {
        "id": "CPCrp3fyH2xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CALL FUNCTION ---\n",
        "add_words_to_graph(wordDF, g, ns)"
      ],
      "metadata": {
        "id": "CYYLmllVH2vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 7: Function to add Segments (based on your dataset)\n",
        "# -------------------------\n",
        "def add_segments_to_graph(segmdf, g, ns):\n",
        "    for _, row in segmdf.iterrows():\n",
        "        seg_id_str = str(row['ID']).strip()\n",
        "        seg_uri = URIRef(ns + seg_id_str)\n",
        "\n",
        "        # parent Word ID = first 3 parts\n",
        "        word_id_str = \"-\".join(seg_id_str.split(\"-\")[:3])\n",
        "        word_uri = URIRef(ns + word_id_str)\n",
        "\n",
        "        # add Segment individual\n",
        "        g.add((seg_uri, RDF.type, ns.QuranicSegment))\n",
        "        g.add((seg_uri, RDFS.label, Literal(str(row['seg']).strip(), lang='ar')))\n",
        "\n",
        "        # link to word\n",
        "        g.add((word_uri, ns.hasQSegment, seg_uri))\n",
        "        g.add((seg_uri, ns.isPartOfWord, word_uri))\n",
        "        g.add((seg_uri, ns.hasBuckwalterSegment, Literal(str(row['buck']).strip(), lang='en')))\n",
        "        # When adding actual values\n",
        "        g.add((seg_uri, ns.hasPOS, Literal(row[\"pos\"], datatype=XSD.string)))\n",
        "\n"
      ],
      "metadata": {
        "id": "I5UiV0l1H2kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_segments_to_graph(segmdf, g, ns)"
      ],
      "metadata": {
        "id": "m-G9qytpIk6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 8: Function to count total verses per Surah using Chapter_Index as Surah URI\n",
        "# -------------------------\n",
        "verses_per_surah = df1.groupby('Chapter_Index')['Verse_ID'].count().to_dict()\n",
        "\n",
        "for chapter_index, total_verses in verses_per_surah.items():\n",
        "    surah_uri = URIRef(ns + str(chapter_index))\n",
        "    g.add((surah_uri, ns.totalVerses_prop, Literal(total_verses)))"
      ],
      "metadata": {
        "id": "0n4Fb_QvJXGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 9: Function to map HadithBooks and add them (based on your dataset and sheets names)\n",
        "# -------------------------\n",
        "\n",
        "hadith_sheet_to_book = {\n",
        "    \"SB\": \"SahihAlBukhari\",\n",
        "    \"MUS\": \"SahihMuslim\",\n",
        "    \"ad\": \"SunanAbuDawood\",\n",
        "    \"TIR\": \"JamiAtTirmidhi\",\n",
        "    \"NES\": \"SunanAnNasai\",\n",
        "    \"im\": \"SunanIbnMajah\"\n",
        "}\n",
        "\n",
        "\n",
        "def add_hadithd_book_to_graph(book_class_name, df, g, ns):\n",
        "    book_uri = ns[book_class_name]  # Refer to existing class URI\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        chapter_uri = URIRef(ns + str(row['Chapter_Index']))\n",
        "        g.add((chapter_uri, RDF.type, ns.HadithChapter))\n",
        "        g.add((chapter_uri, RDFS.label, Literal(row['Chapter_English'], lang='en')))\n",
        "        g.add((chapter_uri, RDFS.label, Literal(row['Chapter_Arabic'], lang='ar')))\n",
        "        g.add((chapter_uri, ns.isPartOf, book_uri))\n",
        "\n",
        "        hadith_uri = URIRef(ns + str(row['Hadith_Index']))\n",
        "        g.add((hadith_uri, RDF.type, ns.HadithText))\n",
        "        g.add((hadith_uri, RDFS.label, Literal(row['English_Hadith'], lang='en')))\n",
        "        g.add((hadith_uri, RDFS.label, Literal(row['Arabic_Hadith'], lang='ar')))\n",
        "        g.add((hadith_uri, ns.isPartOf, chapter_uri))\n",
        "\n",
        "        g.add((hadith_uri, ns.hasIsnad, Literal(row[\"English_Isnad\"], lang=\"en\")))\n",
        "        g.add((hadith_uri, ns.hasIsnad, Literal(row[\"Arabic_Isnad\"], lang=\"ar\")))\n",
        "\n",
        "        g.add((hadith_uri, ns.hasMatn, Literal(row[\"English_Matn\"], lang=\"en\")))\n",
        "        g.add((hadith_uri, ns.hasMatn, Literal(row[\"Arabic_Matn\"], lang=\"ar\")))\n",
        "\n",
        "        g.add((hadith_uri, ns.hasGrade, Literal(row[\"English_Grade\"], lang=\"en\")))\n",
        "        g.add((hadith_uri, ns.hasGrade, Literal(row[\"Arabic_Grade\"], lang=\"ar\")))\n",
        "\n",
        "        if pd.notna(row.get('Topic_Index')):\n",
        "            topic_uri = URIRef(ns + str(row['Topic_Index']))\n",
        "            g.add((topic_uri, RDF.type, ns.HadithTopic))\n",
        "            if pd.notna(row.get('English_Topic')):\n",
        "                g.add((topic_uri, RDFS.label, Literal(row['English_Topic'], lang='en')))\n",
        "            if pd.notna(row.get('Arabic_Topic')):\n",
        "                g.add((topic_uri, RDFS.label, Literal(row['Arabic_Topic'], lang='ar')))\n",
        "            g.add((hadith_uri, ns.discussHadithTopics, topic_uri))"
      ],
      "metadata": {
        "id": "tdHiVMr_Ik0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 10: Function to track chapter and hadith counts\n",
        "# -------------------------\n",
        "\n",
        "chapter_counts = {}\n",
        "hadith_counts = {}\n",
        "\n",
        "# Process Hadith Data & Count Chapters & Hadiths\n",
        "for sheet_name in excel_file.sheet_names:\n",
        "    if sheet_name in hadith_sheet_to_book:\n",
        "        df = excel_file.parse(sheet_name)\n",
        "        if not df.empty:\n",
        "            mapped_book = hadith_sheet_to_book[sheet_name]\n",
        "            add_hadithd_book_to_graph(mapped_book, df, g, ns)\n",
        "\n",
        "            # Count unique chapters and hadiths per book\n",
        "            chapter_counts[mapped_book] = df['Chapter_Index'].nunique()\n",
        "            hadith_counts[mapped_book] = df['Hadith_Index'].nunique()\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Skipped unknown sheet: {sheet_name}\")\n",
        "\n",
        "# Add totalChapters and totalHadiths properties to HadithBook classes\n",
        "for book_name in chapter_counts:\n",
        "    g.add((ns[book_name], ns.totalChapters_prop, Literal(chapter_counts[book_name])))\n",
        "    g.add((ns[book_name], ns.totalHadiths_prop, Literal(hadith_counts[book_name])))"
      ],
      "metadata": {
        "id": "0kI2rqcVIkwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 11: Function to track total Hadith in each chapter\n",
        "# -------------------------\n",
        "from rdflib import RDF, RDFS, Literal\n",
        "from rdflib.namespace import OWL, XSD\n",
        "\n",
        "# ---- Define the property (your snippet + recommended domain/range) ----\n",
        "totalHadithsInChapter = ns[\"totalHadithsInChapter\"]\n",
        "g.add((totalHadithsInChapter, RDF.type, OWL.DatatypeProperty))\n",
        "g.add((totalHadithsInChapter, RDFS.domain, ns[\"HadithChapter\"]))\n",
        "g.add((totalHadithsInChapter, RDFS.range, XSD.integer))\n",
        "g.add((totalHadithsInChapter, RDFS.label, Literal(\"total hadiths in chapter\", lang=\"en\")))\n",
        "g.add((totalHadithsInChapter, RDFS.label, Literal(\"ÿ•ÿ¨ŸÖÿßŸÑŸä ÿßŸÑÿ£ÿ≠ÿßÿØŸäÿ´ ŸÅŸä ÿßŸÑÿ®ÿßÿ®\", lang=\"ar\")))\n",
        "\n",
        "from rdflib import RDF, Literal\n",
        "from rdflib.namespace import XSD\n",
        "\n",
        "def set_total_hadiths_in_chapters_from_graph(g, ns):\n",
        "    \"\"\"\n",
        "    Counts hadiths per chapter using triples:\n",
        "      ?hadith rdf:type :HadithText .\n",
        "      ?hadith :isPartOf ?chapter .\n",
        "      ?chapter rdf:type :HadithChapter .\n",
        "\n",
        "    Writes:\n",
        "      ?chapter :totalHadithsInChapter N .\n",
        "    \"\"\"\n",
        "    isPartOf = ns[\"isPartOf\"]\n",
        "    totalProp = ns[\"totalHadithsInChapter\"]\n",
        "\n",
        "    hadith_cls  = ns[\"HadithText\"]\n",
        "    chapter_cls = ns[\"HadithChapter\"]\n",
        "\n",
        "    # collect all chapters\n",
        "    chapters = set(g.subjects(RDF.type, chapter_cls))\n",
        "\n",
        "    # initialize counts\n",
        "    counts = {ch: 0 for ch in chapters}\n",
        "\n",
        "    # count hadiths linked to each chapter\n",
        "    for h in g.subjects(RDF.type, hadith_cls):\n",
        "        for ch in g.objects(h, isPartOf):\n",
        "            if ch in counts:   # ensures it's a HadithChapter individual\n",
        "                counts[ch] += 1\n",
        "\n",
        "    # write totals (remove old values first)\n",
        "    for ch, n in counts.items():\n",
        "        g.remove((ch, totalProp, None))\n",
        "        g.add((ch, totalProp, Literal(n, datatype=XSD.integer)))\n",
        "\n",
        "    return counts\n",
        "\n",
        "# --- run it ---\n",
        "counts = set_total_hadiths_in_chapters_from_graph(g, ns)\n",
        "\n",
        "# sanity check: print a few\n",
        "for ch, n in list(counts.items())[:10]:\n",
        "    print(ch, n)\n"
      ],
      "metadata": {
        "id": "1dLs_wboJmYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 12: Function to add related Quran and Hadith topics\n",
        "# -------------------------\n",
        "\n",
        "# Load datasets\n",
        "df_related = pd.read_excel(\"yourFileName.xlsx\")\n",
        "#df_unrelated = pd.read_excel(\"yourFileName.xlsx\")\n",
        "\n",
        "# --- Add related topics ---\n",
        "for _, row in df_related.iterrows():\n",
        "    if pd.notna(row[\"QuranTopic_ID\"]) and pd.notna(row[\"HadithTopic_ID\"]):\n",
        "        q_topic = URIRef(ns + row[\"QuranTopic_ID\"])\n",
        "        h_topic = URIRef(ns + row[\"HadithTopic_ID\"])\n",
        "\n",
        "        # Add symmetric relation\n",
        "        g.add((q_topic, relatedTo, h_topic))\n",
        "        # Since it's symmetric, a reasoner (HermiT, Pellet) will infer (h_topic ‚Üí q_topic)\n",
        "\n",
        "# --- Add unrelated topics ---\n",
        "#for _, row in df_unrelated.iterrows():\n",
        "#    if pd.notna(row[\"QuranTopic_ID\"]) and pd.notna(row[\"HadithTopic_ID\"]):\n",
        "#        q_topic = URIRef(ns + row[\"QuranTopic_ID\"])\n",
        "#        h_topic = URIRef(ns + row[\"HadithTopic_ID\"])#\n",
        "\n",
        " #       g.add((q_topic, unrelatedTo, h_topic))\n",
        "        # Note: not symmetric by default (we could make it symmetric too if you want)\n"
      ],
      "metadata": {
        "id": "zQ2LeTyrJmV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 13: Serialize the final ontology (based on the format you seek)\n",
        "# -------------------------\n",
        "\n",
        "g.serialize(\"fileName.ttl\", format=\"turtle\")"
      ],
      "metadata": {
        "id": "yoshtfXbJmSd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}